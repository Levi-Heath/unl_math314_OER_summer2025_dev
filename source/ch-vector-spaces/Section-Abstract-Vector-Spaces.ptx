<?xml version="1.0" encoding="UTF-8"?>

<section xml:id="Section-Abstract-Vector-Spaces" xmlns:xi="http://www.w3.org/2001/XInclude">
    <title>Abstract Vector Spaces</title>
<p>
When we examined subspaces of <m>\R^n</m> we discussed <m>\R^n</m> as a vector space and introduced the notion of a subspace of <m>\R^n</m>.  
In this section we will consider sets other than <m>\R^n</m> that have two operations and satisfy the same properties as <m>\R^n</m>.  Such sets, together with the operations of addition and scalar multiplication, will also be called vector spaces.
</p> 















<subsection xml:id="Section-Bases-and-Dimension-of-Abstract-Vector-Spaces">
    <title>Bases and Dimension of Abstract Vector Spaces</title>



 

<!--
<subsection xml:id="Subsection-Linear-Independence">
    <title>Linear Independence</title>
-->

<p>
When working with <m>\R^n</m> and subspaces of <m>\R^n</m> we developed several fundamental ideas including <term>span</term>, <term>linear independence</term>, <term>bases</term> and <term>dimension</term>.  We will find that these concepts generalize easily to abstract vector spaces and that analogous results hold in these new settings.
</p>



<definition xml:id="def-linearindependenceabstract">
    <title>Linear Independence</title>
    <statement>
        <p>
            Let <m>V</m> be a vector space.  Let <m>\mathbf{v}_1, \mathbf{v}_2,\ldots ,\mathbf{v}_p</m> be vectors of <m>V</m>.  
            We say that the set <m>\{\mathbf{v}_1, \mathbf{v}_2,\ldots ,\mathbf{v}_p\}</m> is <term>linearly independent</term> if the only solution to 

<me>
    a_1\mathbf{v}_1+a_2\mathbf{v}_2+\ldots +a_p\mathbf{v}_p=\mathbf{0}
</me>

is the <term>trivial solution</term> <m>a_1=a_2=\ldots =a_p=0</m>.
</p> 

        <p> 
If, in addition to the trivial solution, a <term>non-trivial solution</term> (not all <m>a_1, a_2,\ldots ,a_p</m> are zero) exists, 
then we say that the set <m>\{\mathbf{v}_1, \mathbf{v}_2,\ldots ,\mathbf{v}_p\}</m> is <term>linearly dependent</term>.
        </p>
    </statement>
</definition>


<p> 
Let us examine this abstract version of bases in the context of polynomials, to get a feeling for these concepts.
</p> 

<example xml:id="ex-polyindset">
    <statement>
        <p>
            Show that <m>P=\{1 + x, 3x + x^{2}, 2 + x - x^{2}\}</m> is linearly independent in <m>\mathbb{P}^{2}</m>.
       </p>
    </statement>
    <answer>
        <p>
            Consider the linear combination equation
<md>
<mrow> a(1 + x) + b(3x + x^2) + c(2 + x - x^2) \amp = 0 </mrow>
<mrow> a+ax+3bx+bx^2+2c+cx-cx^2\amp =0 </mrow> 
<mrow> (a+2c)+(a+3b+c)x+(b-c)x^2\amp =0 </mrow>
</md>

The constant term, as well as the coefficients in front of <m>x</m> and <m>x^2</m>, must be equal to <m>0</m>.  This gives us the following system of equations.
<me>
\begin{array}{rlrlrcr}
	a \amp  + \amp       \amp  + \amp  2c \amp  = \amp  0 \\
	a \amp  + \amp  3b \amp  + \amp   c \amp  = \amp  0 \\
	    \amp    \amp   b \amp  - \amp   c \amp  = \amp  0 \\
\end{array}
</me>
The only solution is <m>a = b = c = 0</m>.  We conclude that <m>P</m> is linearly independent in <m>\mathbb{P}^2</m>.
       </p>
    </answer>
</example>
</subsection>











<subsection xml:id="Subsection-Bases-and-Dimension">
    <title>Bases and Dimension</title>

<p>
Recall that our motivation for defining a basis of a subspace of <m>\R^n</m> was to have a collection of vectors such that every vector of the subspace can be expressed as a unique linear combination of the vectors in that collection.  Definition of a basis (<xref ref="def-basis"/>) generalizes to abstract vector spaces as follows.
</p>


<definition xml:id="def-basisabstract">

    <statement>
        <p>
            Let <m>V</m> be a vector space.  A set <m>\mathcal{B}</m> of vectors of <m>V</m> is called a <term>basis</term> of <m>V</m> provided that 
<ol>
<li xml:id="item-defbasis1abstract">
  <p> 
<m>\mbox{span}(\mathcal{B})=V</m>  </p>
</li>
<li xml:id="item-defbasis2abstract">
  <p> 
<m>\mathcal{B}</m> is linearly independent. </p>
</li>
</ol>
        </p>
    </statement>
</definition>

<theorem xml:id="th-uniquerep">

    <statement>
        <p>
            Let <m>V</m> be a vector space, and let <m>\mathcal{B}=\{\mathbf{v}_1, \mathbf{v}_2,\ldots,\mathbf{v}_n\}</m> be a basis for <m>V</m>.  Then every element <m>\mathbf{v}</m> of <m>V</m> has a unique representation as linear combination of the elements of <m>\mathcal{B}</m>.
        </p>
    </statement>

<proof>
    <p>
By the definition of a basis, we know that <m>\mathbf{v}</m> can be written as a linear combination of <m>\mathbf{v}_1, \mathbf{v}_2,\ldots,\mathbf{v}_n</m>.  Suppose there are two such representations.  Then,

<me>
    \mathbf{v}=a_1\mathbf{v}_1+ a_2\mathbf{v}_2+\ldots+a_n\mathbf{v}_n
</me>


<me>
    \mathbf{v}=b_1\mathbf{v}_1+ b_2\mathbf{v}_2+\ldots+b_n\mathbf{v}_n
</me>

But then we have:
<md>
<mrow> a_1\mathbf{v}_1+ a_2\mathbf{v}_2+\ldots+a_n\mathbf{v}_n =b_1\mathbf{v}_1+ b_2\mathbf{v}_2+\ldots+b_n\mathbf{v}_n </mrow> 
<mrow> a_1\mathbf{v}_1+ a_2\mathbf{v}_2+\ldots+a_n\mathbf{v}_n-(b_1\mathbf{v}_1+ b_2\mathbf{v}_2+\ldots+b_n\mathbf{v}_n)\amp =\mathbf{0} </mrow>
<mrow> (a_1-b_1)\mathbf{v}_1+ (a_2-b_2)\mathbf{v}_2+\ldots+(a_n-b_n)\mathbf{v}_n\amp =\mathbf{0}  </mrow>
</md>
Because <m>\mathbf{v}_1, \mathbf{v}_2,\ldots,\mathbf{v}_n</m> are linearly independent, we have <m>a_i-b_i=0</m> for <m>1\leq i\leq n</m>. Consequently <m>a_i=b_i</m> for <m>1\leq i\leq n</m>.
    </p>
</proof>
</theorem>

<p>
In chapter <m>5</m>, we defined the dimension of a subspace of <m>\R^n</m> to be the number of elements in a basis (<xref ref="def-dimension"/>).  We will adopt this definition for abstract vector spaces.  As before, to ensure that <term>dimension</term> is well-defined we need to establish that this definition is independent of our choice of a basis.  The proof of the following theorem is identical to the proof of its counterpart in <m>\R^n</m>  (<xref ref="th-dimwelldefined"/>).
</p>

<theorem xml:id="th-dimwelldefinedabstract">

    <statement>
        <p>
            Let <m>V</m> be a vector space.  Suppose <m>\mathcal{B}=\{\mathbf{v}_1, \mathbf{v}_2,\ldots ,\mathbf{v}_t\}</m> and <m>\mathcal{C}=\{\mathbf{w}_1, \mathbf{w}_2,\ldots ,\mathbf{w}_s\}</m> be two bases of <m>V</m>.  Then <m>s=t</m>.
        </p>
    </statement>
</theorem>

<p>
Now we can state the definition of dimensions for abstract vector spaces.
</p> 


<definition xml:id="def-dimensionabstract">

    <statement>
        <p>
            Let <m>V</m> be a subspace of a vector space <m>W</m>.  The <term>dimension</term> of <m>V</m> is the number, <m>m</m>, of elements in any basis of <m>V</m>.  We write

<me>
    \mbox{dim}(V)=m.
</me>
        </p>
    </statement>
</definition>

<p>
In our discussions up to this point, we have always assumed that a basis is nonempty and hence that the dimension of the space is at least <m>1</m>. However, the zero space <m>\{\mathbf{0}\}</m> has <em>no</em> basis.  To accommodate for this, we will say that the zero vector space <m>\{\mathbf{0}\}</m> is defined to have dimension <m>0</m>:
<me>
\mbox{dim }\{\mathbf{0}\} = 0.
</me>

Our insistence that <m>\mbox{dim}\{\mathbf{0}\} = 0</m> amounts to saying that the empty set of vectors is a basis of <m>\{\mathbf{0}\}</m>. Thus the statement that ``the dimension of a vector space is the number of vectors in any basis'' holds even for the zero space. 
</p>


<example xml:id="ex-dimofM">
    <statement>
        <p>
            Recall that the vector space <m>\mathbb{M}_{m,n}</m> consists of all <m>m\times n</m> matrices (see <xref ref="ex-MLexamplesofvectspaces"/>.  Find a basis and the dimension of <m>\mathbb{M}_{m,n}</m>.
       </p>
    </statement>
    <answer>
        <p>
            Let <m>\mathcal{B}</m> consist of <m>m\times n</m> matrices 
 with exactly one entry equal to <m>1</m> and all other entries equal to <m>0</m>. It is clear that every <m>m\times n</m> matrix can be written as a linear combination of elements of <m>\mathcal{B}</m>.  It is also easy to see that the elements of <m>\mathcal{B}</m> are linearly independent.  Thus <m>\mathcal{B}</m> is a basis for <m>\mathbb{M}_{m,n}</m>.  The set <m>\mathcal{B}</m> contains <m>mn</m> elements, so <m>\mbox{dim}(\mathbb{M}_{m,n})=mn</m>.
       </p>
    </answer>
</example>

<example xml:id="ex-dimofP">
    <statement>
        <p>
            Recall that <m>\mathbb{P}^n</m> is the set of all polynomials of degree <m>n</m> or less (see <xref ref="ex-pnisavectorspace"/>. Show that <m>\mbox{dim}( \mathbb{P}^{n}) = n + 1</m> and that 
            <me>
            \lbrace 1, x, x^{2}, \dots, x^{n} \rbrace
            </me>
            
            is a basis of <m>\mathbb{P}^{n}</m>.
       </p>
    </statement>
    <answer>
        <p>
            Each polynomial
            <me>
            p(x) = a_{0} + a_{1}x + \ldots + a_{n}x^{n}, \quad \text{in } \mathbb{P}^{n},
            </me>
            
            is clearly a linear combination of <m>1, x, \dots, x^{n}</m>, so 
            <me>
            \mathbb{P}^{n} = \mbox{span} \lbrace 1, x, \dots, x^{n} \rbrace.
            </me>. 

Suppose <m>a_{0}1 + a_{1}x + \dots + a_{n}x^{n} = 0</m>, then <m>a_{0} = a_{1} = \ldots = a_{n} = 0</m>. So <m>\{1, x, \dots, x^{n}\}</m> is linearly independent and is therefore a basis containing <m>n + 1</m> vectors. Thus, <m>\mbox{dim}(\mathbb{P}^{n}) = n + 1</m>.
       </p>
    </answer>
</example>

<example xml:id="ex-CAbasis">
    <statement>
        <p>
            Consider the subset
<me>
C_A = \lbrace X \in\mathbb{M}_{2,2} : AX = XA \rbrace.
</me>
of <m>\mathbb{M}_{2,2}</m>. 

It was shown in <xref ref="ex-centralizerofA"/> of  that <m>C_A</m> is a subspace for any choice of the matrix <m>A</m>.

Let <me>
A = 
\begin{bmatrix}
1 \amp  1 \\
0 \amp  0
\end{bmatrix}.
</me>

Show that <m>\mbox{dim}(C_A) = 2</m> and find a basis of <m>C_A</m>.
       </p>
    </statement>
    <answer>
        <p>
            Suppose 
<me>X = 
\begin{bmatrix}
a \amp  b \\
c \amp  d
\end{bmatrix}
</me>
 
is in <m>C_A</m>. Then
 
<me>
    \begin{bmatrix}1\amp 1\\0\amp 0\end{bmatrix}\begin{bmatrix}a\amp b\\c\amp d\end{bmatrix}=\begin{bmatrix}a\amp b\\c\amp d\end{bmatrix}\begin{bmatrix}1\amp 1\\0\amp 0\end{bmatrix}.
</me>

 
<me>
    \begin{bmatrix}a+c\amp b+d\\0\amp 0\end{bmatrix}=\begin{bmatrix}a\amp a\\c\amp c\end{bmatrix}.
</me>

 This gives us two relationships:  
 
<me>
    b+d=a\quad\text{and}\quad c=0.
</me>

 We can now express a generic element <m>X</m> of <m>C_A</m> as
 
<md>
<mrow>    X=\begin{bmatrix}a\amp b\\c\amp d\end{bmatrix} \amp = \begin{bmatrix}b+d\amp b\\0\amp d\end{bmatrix}  </mrow>
<mrow>    \amp =\begin{bmatrix}b\amp b\\0\amp 0\end{bmatrix}+\begin{bmatrix}d\amp 0\\0\amp d\end{bmatrix}  </mrow>
<mrow>    \amp =b\begin{bmatrix}1\amp 1\\0\amp 0\end{bmatrix}+d\begin{bmatrix}1\amp 0\\0\amp 1\end{bmatrix}. </mrow>
</md>

 
Let 

<me>
    \mathcal{B}=\left \lbrace \begin{bmatrix}1\amp 1\\0\amp 0\end{bmatrix},\begin{bmatrix}1\amp 0\\0\amp 1\end{bmatrix}\right \rbrace.
</me>


The set <m>\mathcal{B}</m> is linearly independent (see <xref ref="prob-CABlinind"/>) Every element <m>X</m> of <m>C_A</m> can be written as a linear combination of elements of <m>\mathcal{B}</m>.  Thus <m>C_A=\mbox{span}\mathcal{B}</m>.
 Therefore <m>\mathcal{B}</m> is a basis of <m>C_A</m>, and <m>\mbox{dim}(C_A) = 2</m>.
       </p>
    </answer>
</example>

<example xml:id="ex-symmetricmatsubspace">
    <statement>
        <p>
            In <xref ref="prob-symmetricsubspace"/> of you demonstrated that the set of all symmetric <m>n\times n</m> matrices is a subspace of <m>\mathbb{M}_{n,n}</m>.

Let <m>V</m> be a subspace of <m>\mathbb{M}_{2,2}</m> consisting of all <m>2\times 2</m> symmetric matrices.  Find the dimension of <m>V</m>.
       </p>
    </statement>
    <answer>
        <p>
            A matrix <m>A</m> is symmetric if <m>A^{T} = A</m>. In other words, a matrix <m>A</m> is symmetric when entries directly across the main diagonal are equal, so each <m>2 \times 2</m> symmetric matrix has the form

<me>
\begin{bmatrix}
a \amp  c \\
c \amp  b
\end{bmatrix}
= a\begin{bmatrix}
1 \amp  0 \\
0 \amp  0
\end{bmatrix}
+ b\begin{bmatrix}
0 \amp  0 \\
0 \amp  1
\end{bmatrix}
+ c\begin{bmatrix}
0 \amp  1 \\
1 \amp  0
\end{bmatrix}.
</me>

Hence the set 
<me>\mathcal{B} = \left \lbrace
\begin{bmatrix}
1 \amp  0 \\
0 \amp  0
\end{bmatrix}, \begin{bmatrix}
0 \amp  0 \\
0 \amp  1
\end{bmatrix}, \begin{bmatrix}
0 \amp  1 \\
1 \amp  0
\end{bmatrix}
\right \rbrace </me>
 spans <m>V</m>. The reader can verify that <m>\mathcal{B}</m> is linearly independent. Thus <m>\mathcal{B}</m> is a basis of <m>V</m>, so <m>\mbox{dim}(V) = 3</m>.
       </p>
    </answer>
</example>
</subsection>








<subsection xml:id="Subsection-Finite-Dimensional-Vector-Spaces">
    <title>Finite-Dimensional Vector Spaces</title>

    <p>
Our definition of dimension of a vector space depends on the vector space having a basis.  In this section we will establish that any vector space spanned by finitely many vectors has a basis.
    </p>


<definition xml:id="def-findimvectorspace">

    <statement>
        <p>
            A vector space is said to be <term>finite-dimensional</term> if it is spanned by finitely many vectors.
        </p>
    </statement>
</definition>

<p>
Given a finite-dimensional vector space <m>V</m> we will find a basis for <m>V</m> by starting with a linearly independent subset of <m>V</m> and expanding it to a basis.  The following results are more general versions of <xref ref="lemma-atmostnlinindinrn"/> and <xref ref="lemma-expandinglinindset"/>, and <xref ref="th-dimwelldefined"/>.  The proofs are identical and we will omit them.
</p>

<lemma xml:id="lemma-atmostnlinindinabstract">

    <statement>
        <p>
            Let <m>V</m> be a vector space spanned by <m>n</m> vectors.  If a linearly independent subset <m>S</m> of <m>V</m> contains <m>m</m> vectors, then <m>m\leq n</m>.
        </p>
    </statement>
</lemma>

<lemma xml:id="lemma-expandinglinindsetabstract">

    <statement>
        <p>
            Let <m>V</m> be a vector space.  Let <m>\{\mathbf{v}_1,\ldots ,\mathbf{v}_k\}</m> be a linearly independent subset of <m>V</m>.  If <m>\mathbf{u}</m> is not in <m>\mbox{span}(\mathbf{v}_1,\ldots ,\mathbf{v}_k)</m>, then <m>\{\mathbf{u},\mathbf{v}_1,\ldots ,\mathbf{v}_k\}</m> is linearly independent.
        </p>
    </statement>
</lemma>

<theorem xml:id="th-expandtobasisabstract">

    <statement>
        <p>
            Let <m>V</m> be a finite-dimensional vector space.  Any linearly independent subset of <m>V</m> can be expanded to a basis of <m>V</m>.
        </p>
    </statement>
</theorem>
</subsection>




















<subsection xml:id="Subsection-Coordinate-Vectors">
    <title>Coordinate Vectors</title>

<p>
Recall that in the context of <m>\R^n</m> (and subspaces of <m>\R^n</m>) the requirement that elements of a basis be linearly independent guarantees that every element of the vector space has a <em>unique</em> representation in terms of the elements of the basis.  (See Theorem <xref ref="th-linindbasis"/> of <url href="https://ximera.osu.edu/oerlinalg/LinearAlgebra/VSP-0030/main">Introduction to Bases</url>)  We proved the same property for abstract vector spaces in Theorem <xref ref="th-uniquerep"/>.
</p> 

<p>
Uniqueness of representation in terms of the elements of a basis allows us to associate every element of a vector space <m>V</m> with a unique <term>coordinate vector</term> with respect to a given basis.  Coordinate vectors were first introduced in <url href="https://ximera.osu.edu/oerlinalg/LinearAlgebra/VSP-0030/main">Introduction to Bases</url>.  We now give a formal definition.
</p>

<definition xml:id="def-coordvector">

    <statement>
        <p>
            Let <m>V</m> be a vector space, and let <m>\mathcal{B}=\{\mathbf{v}_1, \ldots ,\mathbf{v}_n\}</m> be a basis for <m>V</m>.  If <m>\mathbf{v}=a_1\mathbf{v}_1+\ldots +a_n\mathbf{v}_n</m>, then the vector in <m>\R^n</m> whose components are the coefficients <m>a_1, \ldots ,a_n</m>  is said to be the <term>coordinate vector</term> for <m>\mathbf{v}</m> with respect to <m>\mathcal{B}</m>.  We denote the coordinate vector by <m>[\mathbf{v}]_{\mathcal{B}}</m> and write:

<me>
    [\mathbf{v}]_{\mathcal{B}}=\begin{bmatrix}a_1\\\vdots \\a_n\end{bmatrix}.
</me>
        </p>
    </statement>
</definition>

<remark xml:id="coordVectorOrder">
<statement>
    <p>
The order of in which vectors <m>\mathbf{v}_1, \ldots ,\mathbf{v}_n</m> appear in <m>\mathcal{B}</m> of <xref ref="def-coordvector"/> is important.  Switching the order of these vectors would switch the order of the coordinate vector components.  For this reason, we will often use the term <term>ordered basis</term> to describe <m>\mathcal{B}</m> in the context of coordinate vectors.
    </p>
</statement>
</remark>



<p> 
Coordinate vectors may seem abstract as described above. In examples, however, one can nearly always pinpoint exactly what the coordinates are. Some examples will emphaize this:
</p> 


<example xml:id="ex-coordvectorinpolyvectspace">
    <p>
        The coordinate vector for <m>p(x)=4-3x^2+5x^3</m> in <m>\mathbb{P}^4</m> with respect to the ordered basis <m>\mathcal{B}_1=\{1, x, x^2, x^3, x^4\}</m> is 

<me>
    [p(x)]_{\mathcal{B}_1}=\begin{bmatrix}4\\0\\-3\\5\\0\end{bmatrix}.
</me>

Now let's change the order of the elements in <m>\mathcal{B}_1</m>.  The coordinate vector for <m>p(x)=4-3x^2+5x^3</m> with respect to the ordered basis <m>\mathcal{B}_2=\{x^4, x^3, x^2, x, 1\}</m> is 

<me>
    [p(x)]_{\mathcal{B}_2}=\begin{bmatrix}0\\5\\-3\\0\\4\end{bmatrix}.
</me>
    </p>
</example>

<example xml:id="ex-coordvectorinpolyvectspace2">
    <statement>
        <p>
            Show that the set <m>\mathcal{B}=\{x, 1+x, x+x^2\}</m> is a basis for <m>\mathbb{P}^2</m>. Keep the order of elements in <m>\mathcal{B}</m> and find the coordinate vector for <m>p(x)=4-x+3x^2</m> with respect to the ordered basis <m>\mathcal{B}</m>.
       </p>
    </statement>
    <answer>
        <p>
            We will begin by showing that the elements of <m>\mathcal{B}</m> are linearly independent.  Suppose 

<me>
    ax+b(1+x)+c(x+x^2)=0.
</me>

Then

<me>
    b+(a+b+c)x+cx^2=0.
</me>

This gives us the following system of equations:

<me>
    \begin{array}{ccccccc}
     \amp  \amp b\amp \amp \amp =\amp 0 
     a \amp  +\amp b\amp +\amp c\amp = \amp 0 
	 \amp  \amp \amp \amp c\amp =\amp 0 
     \end{array}  
</me>

The solution <m>a=b=c=0</m> is unique.  We conclude that <m>\mathcal{B}</m> is linearly independent.
</p>

<p>
Next, we need to show that <m>\mathcal{B}</m> spans <m>\mathbb{P}^2</m>.  To this end, we will consider a generic element <m>p(x)=\alpha+\beta x+\gamma x^2</m> of <m>\mathbb{P}^2</m> and attempt to express it as a linear combination of the elements of <m>\mathcal{B}</m>.

<me>
    ax+b(1+x)+c(x+x^2)=\alpha+\beta x+\gamma x^2.
</me>

then

<me>
    b+(a+b+c)x+cx^2=\alpha+\beta x+\gamma x^2. 
</me>

Setting the coefficients of like terms equal to each other gives us

<me>
    \begin{array}{ccccccc}
     \amp  \amp b\amp \amp \amp =\amp \alpha\\
     a \amp  +\amp b\amp +\amp c\amp = \amp \beta \\
	 \amp  \amp \amp \amp c\amp =\amp \gamma
     \end{array}
</me>

Solving this linear system of <m>a</m>, <m>b</m> and <m>c</m> gives us

<me>
    a=\beta-\alpha-\gamma,\quad b=\alpha,\quad c=\gamma .
</me>

(You should verify this.)  This shows that every element of <m>\mathbb{P}^2</m> can be written as a linear combination of elements of <m>\mathcal{B}</m>.  Therefore <m>\mathcal{B}</m> is a basis for <m>\mathbb{P}^2</m>.

To find the coordinate vector for <m>p(x)=4-x+3x^2</m> with respect to <m>\mathcal{B}</m> we need to express <m>p(x)</m> as a linear combination of the elements of <m>\mathcal{B}</m>.  Fortunately, we have already done all the necessary work.  For <m>p(x)</m>, <m>\alpha=4</m>, <m>\beta=-1</m> and <m>\gamma=3</m>.  This gives us the coefficients of the linear combination: <m>a=\beta-\alpha-\gamma=-8</m>, <m>b=\alpha=4</m>, <m>c=\gamma=3</m>.  We now write <m>p(x)</m> as a linear combination

<me>
    p(x)=-8(x)+4(1+x)+3(x+x^2)
</me>

The coordinate vector for <m>p(x)</m> with respect to <m>\mathcal{B}</m> is

<me>
    [p(x)]_{\mathcal{B}}=\begin{bmatrix}-8\\4\\3\end{bmatrix}
</me>
       </p>
    </answer>
</example>

<example xml:id="ex-symmmatsubspace">
    <statement>
        <p>
            Recall that the set <m>V</m> of all symmetric <m>2\times 2</m> matrices is a subspace of <m>\mathbb{M}_{2,2}</m>.  In <xref ref="ex-symmetricmatsubspace"/>, we demonstrated that 
<me>\mathcal{B} = \left \lbrace
\begin{bmatrix}
1 \amp  0 \\
0 \amp  0
\end{bmatrix}, \begin{bmatrix}
0 \amp  0 \\
0 \amp  1
\end{bmatrix}, \begin{bmatrix}
0 \amp  1 \\
1 \amp  0
\end{bmatrix}
\right \rbrace</me> 

is a basis for <m>V</m>.  
Let <m>A=\begin{bmatrix}2\amp -3\\-3\amp 1\end{bmatrix}</m>.  Observe that <m>A</m> is an element of <m>V</m>.

<ol>
<li>
      <p> Find the coordinate vector with respect to the ordered basis <m>\mathcal{B}</m> for <m>A</m>. </p>
</li>

<li>
      <p> Let 
<me>\mathcal{B}'=\left \lbrace 
 \begin{bmatrix}
0 \amp  0 \\
0 \amp  1
\end{bmatrix}, 
\begin{bmatrix}
1 \amp  0 \\
0 \amp  0
\end{bmatrix},
\begin{bmatrix}
0 \amp  1 \\
1 \amp  0
\end{bmatrix}
\right \rbrace </me> 

be another ordered basis for <m>V</m>.  Find the coordinate vector for <m>A</m> with respect to <m>\mathcal{B}'</m>.
</p>
</li>
</ol>
       </p>
    </statement>
    <answer>
        <p>
            We write <m>A</m> as a linear combination of the elements of <m>\mathcal{B}</m>.

<me>
    A=\begin{bmatrix}2\amp -3\\-3\amp 1\end{bmatrix}=2\begin{bmatrix}1\amp 0\\0\amp 0\end{bmatrix}+\begin{bmatrix}
0 \amp  0 \\
0 \amp  1
\end{bmatrix}-3\begin{bmatrix}
0 \amp  1 \\
1 \amp  0
\end{bmatrix}
</me>

Thus, the coordinate vector with respect to <m>\mathcal{B}</m> is

<me>
    [A]_{\mathcal{B}}=\begin{bmatrix}2\\1\\-3\end{bmatrix}
</me>

The coordinate vector with respect to <m>\mathcal{B}'</m> is

<me>
    [A]_{\mathcal{B}'}=\begin{bmatrix}1\\2\\-3\end{bmatrix}.
</me>
       </p>
    </answer>
</example>

<p>
Coordinate vectors will play a vital role in establishing one of the most fundamental results in linear algebra, that all <m>n</m>-dimensional vector spaces have the same structure as <m>\R^n</m>.  In <xref ref="ex-p2isor3"/>, for instance, we will show that <m>\mathbb{P}^2</m> is essentially the same as <m>\R^3</m>.  
</p>
</subsection>





































<exercises>

<!--exercises on Bases start here-->


<exercise xml:id="prob-CABlinind">
    <statement>
        <p>
            Prove that set 
    <me>
    \mathcal{B}=\left\{\begin{bmatrix}1\amp 1\\0\amp 0\end{bmatrix},\begin{bmatrix}1\amp 0\\0\amp 1\end{bmatrix}\right\}
    </me>
    
    of <xref ref="ex-CAbasis"/> is linearly independent.
        </p>
    </statement>
</exercise>



<exercisegroup>
<introduction>
    <p>
        Show that each of the following sets of vectors is linearly independent.
    </p>
</introduction>

<exercise xml:id="prob-linindabstractvsp1">
    <statement>
        <p>
            <me>
    \lbrace 1 + x, 1 - x, x + x^{2} \rbrace \quad \text{in } \mathbb{P}^{2}.
</me>
        </p>
    </statement>
</exercise>

<exercise xml:id="prob-linindabstractvsp2">
    <statement>
        <p>
            <me>
    \lbrace x^{2}, x + 1, 1 - x - x^{2} \rbrace  \quad \text{in } \mathbb{P}^{2}.
</me>
        </p>
    </statement>
</exercise>

<exercise xml:id="prob-linindabstractvsp3">
    <statement>
        <p>
            <me>
\left \lbrace
\begin{bmatrix}
1 \amp  1 \\
0 \amp  0
\end{bmatrix}
, 
\begin{bmatrix}
1 \amp  0 \\
1 \amp  0
\end{bmatrix}
, 
\begin{bmatrix}
0 \amp  0 \\
1 \amp  -1
\end{bmatrix}
,\
\begin{bmatrix}
0 \amp  1 \\
0 \amp  1
\end{bmatrix}
\right \rbrace \quad \text{in } \mathbb{M}_{2,2}.
</me>
 
</p>
    </statement>
</exercise>
</exercisegroup>




<exercise xml:id="prob-linindabstractvsp123">
    <statement>
        <p>
            Show that each set in <xref ref="prob-linindabstractvsp1"/>-<xref ref="prob-linindabstractvsp3"/> is a basis for its respective vector space.
        </p>
    </statement>
</exercise>



<exercisegroup>
<introduction>
    <p>
        Find the coordinate vector for <m>p(x)=6-2x+4x^2</m> with respect to the given ordered basis <m>\mathcal{B}</m> of <m>\mathbb{P}^2</m>.
    </p>
</introduction>

<exercise xml:id="prob-coordvectors1">
    <statement>
        <p>
            <me>
    \mathcal{B}= \lbrace 1 + x, 1 - x, x + x^{2} \rbrace.
</me>
        </p>
    </statement>
    <answer>
        <p>
            <me>
    [p(x)]_{\mathcal{B}}=\begin{bmatrix}0\\6\\4\end{bmatrix}.
</me>
        </p>
    </answer>
</exercise>

<exercise xml:id="prob-coordvectors2">
    <statement>
        <p>
            <me>
    \mathcal{B}=\{x^{2}, x + 1, 1 - x - x^{2}\}.
</me>
        </p>
    </statement>
    <answer>
        <p>
            <me>
    [p(x)]_{\mathcal{B}}=\begin{bmatrix}8\\2\\4\end{bmatrix}.
</me>
        </p>
    </answer>
</exercise>
</exercisegroup>





<exercise xml:id="prob-coordvectors3">
    <statement>
        <p>
            Find the coordinate vector for
            <me>
            A=\begin{bmatrix}4\amp -3\\1\amp 2\end{bmatrix}
            </me>
            
            with respect to the ordered basis
<me>
    \mathcal{B}=
\left \lbrace
\begin{bmatrix}
1 \amp  1 \\
0 \amp  0
\end{bmatrix}
, 
\begin{bmatrix}
1 \amp  0 \\
1 \amp  0
\end{bmatrix}
, 
\begin{bmatrix}
0 \amp  0 \\
1 \amp  -1
\end{bmatrix}
,\
\begin{bmatrix}
0 \amp  1 \\
0 \amp  1
\end{bmatrix}
\right \rbrace.
</me>
        </p>
    </statement>
    <answer>
        <p>
            <me>
    [A]_{\mathcal{B}}=\begin{bmatrix}-1\\5\\-4\\-2\end{bmatrix}.
</me>
        </p>
    </answer>
</exercise>

<exercise xml:id="prob-basisforabstractvectspace">
    <statement>
        <p>
            Let <m>V</m> be a vector space of dimension <m>3</m>.  Suppose <m>S=\{\mathbf{v}_1, \mathbf{v}_2, \mathbf{v}_3\}</m> is linearly independent in <m>V</m>.  Show that <m>S</m> is a basis for <m>V</m>.
        </p>
    </statement>
</exercise>







</exercises> 
</section>